# ğŸ’£ BOMBA B-03: CÃ“DIGO ÃCARO
## Nivel de Amenaza: â­â­â­â­â˜† (Avanzado)

```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘  OPERACIÃ“N EQUIPO DINAMITA - MÃXIMA PRIORIDAD             â•‘
â•‘  Bomba: B-03 "ÃCARO"                                       â•‘
â•‘  Estado: CRÃTICO - REQUIERE EXPERTO                        â•‘
â•‘  Tiempo lÃ­mite: 20:00 minutos                              â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

---

## âš ï¸ ADVERTENCIA CRÃTICA

La **Bomba B-03** es una de las mÃ¡s peligrosas. Requiere:
- AnÃ¡lisis estadÃ­stico avanzado
- ManipulaciÃ³n de datos temporales complejos
- Entendimiento de distribuciones y percentiles
- **Pensamiento crÃ­tico en CADA paso**

**NO asumas** que los mÃ©todos de B-01 o B-02 funcionarÃ¡n aquÃ­.

---

## ğŸ” PREPARACIÃ“N EXPERTA

```python
import pandas as pd
import numpy as np
from datetime import datetime, timedelta

df_completo = pd.read_csv('dataset_bombas_completo.csv')
df = df_completo[df_completo['ID_Bomba'] == 'B-03'].copy()
df['Timestamp'] = pd.to_datetime(df['Timestamp'])

# ValidaciÃ³n inicial
assert len(df) > 0, "No se encontraron datos para B-03"
print(f"Dataset B-03 cargado: {len(df)} registros")
print(f"Columnas disponibles: {df.columns.tolist()}")
```

---

## ğŸ§© MÃ“DULO 1: Suma Ponderada por Prioridad

**Complejidad:** â­â­â­â­

### DesafÃ­o AVANZADO
No uses suma directa. Usa suma **ponderada** por prioridad:

1. Asigna pesos a cada prioridad:
   - `CrÃ­tica`: peso 2.0
   - `Alta`: peso 1.5
   - `Media`: peso 1.0
   - `Baja`: peso 0.5

2. Calcula: `Î£(Nivel_Amenaza Ã— peso_prioridad)`

3. Aplica la regla binaria sobre este valor ponderado

### ğŸ’¡ ImplementaciÃ³n
```python
pesos = {'CrÃ­tica': 2.0, 'Alta': 1.5, 'Media': 1.0, 'Baja': 0.5}
df['Peso'] = df['Prioridad'].map(pesos)
suma_ponderada = (df['Nivel_Amenaza'] * df['Peso']).sum()
```

### ğŸ¤” ReflexiÃ³n
Â¿Por quÃ© una amenaza "CrÃ­tica" debe contar el doble que una "Media"?

---

## ğŸ§© MÃ“DULO 2: Promedio ArmÃ³nico de Intensidad

**Complejidad:** â­â­â­â­â­

### DesafÃ­o MATEMÃTICO
No uses promedio aritmÃ©tico. Usa **promedio armÃ³nico**:

La fÃ³rmula del promedio armÃ³nico es:
$$H = \frac{n}{\sum_{i=1}^{n} \frac{1}{x_i}}$$

1. Crea variable: `Intensidad = Energia Ã— Frecuencia`
2. Calcula el promedio armÃ³nico de `Intensidad`
3. Toma Ãºltimos 2 dÃ­gitos + 2026

### ğŸ’¡ CÃ³digo
```python
from scipy.stats import hmean  # O implementaciÃ³n manual

intensidad = df['Energia'] * df['Frecuencia']
# Nota: hmean no acepta valores 0
promedio_armonico = hmean(intensidad[intensidad > 0])
```

### ğŸ¯ Â¿Por quÃ© armÃ³nico?
El promedio armÃ³nico penaliza valores extremadamente bajos, siendo Ãºtil para detectar anomalÃ­as en sistemas elÃ©ctricos.

### ğŸ“š ImplementaciÃ³n Manual
```python
n = len(intensidad)
suma_reciprocos = sum(1/x for x in intensidad if x > 0)
promedio_armonico = n / suma_reciprocos
```

---

## ğŸ§© MÃ“DULO 3: Estabilidad Multi-Percentil

**Complejidad:** â­â­â­â­

### DesafÃ­o ESTADÃSTICO
1. Calcula percentil 90 (P90) y percentil 10 (P10) de `Frecuencia`
2. Calcula el rango inter-percentil: `P90 - P10`
3. Regla modificada:
   - Rango > **150**: UNSTABLE
   - Rango â‰¤ **150**: STABLE

### ğŸ’¡ CÃ³digo
```python
p90 = df['Frecuencia'].quantile(0.90)
p10 = df['Frecuencia'].quantile(0.10)
rango_percentil = p90 - p10
```

### ğŸ¤” Â¿Por quÃ© percentiles y no max-min?
Los percentiles son mÃ¡s robustos contra outliers extremos.

---

## ğŸ§© MÃ“DULO 4: Cable por Mediana de EnergÃ­a

**Complejidad:** â­â­â­

### DesafÃ­o
1. Agrupa por `Hex_Cable`
2. Calcula la **mediana** (no suma ni promedio) de `Energia` por cable
3. El cable con mayor mediana es el dominante

### ğŸ’¡ RazÃ³n
La mediana es mÃ¡s robusta que el promedio contra valores atÃ­picos.

```python
medianas = df.groupby('Hex_Cable')['Energia'].median()
cable_dom = medianas.idxmax()
```

---

## ğŸ§© MÃ“DULO 5: Agentes en Zona de Riesgo Extremo

**Complejidad:** â­â­â­â­

### DesafÃ­o TRIPLE CONDICIÃ“N
Cuenta agentes Ãºnicos que cumplan **TODAS** estas condiciones:
1. `Energia > 55` (umbral mÃ¡s alto que B-02)
2. `Nivel_Amenaza > mediana_amenaza` (amenaza sobre la mediana de B-03)
3. `Estado == 'Activo'` o `Estado == 'Verificado'`

### ğŸ’¡ ImplementaciÃ³n
```python
mediana_amenaza = df['Nivel_Amenaza'].median()
df_extremo = df[
    (df['Energia'] > 55) &
    (df['Nivel_Amenaza'] > mediana_amenaza) &
    (df['Estado'].isin(['Activo', 'Verificado']))
]
num_agentes = df_extremo['Agente'].nunique()
```

### ğŸ¯ AnÃ¡lisis
Â¿QuÃ© porcentaje de los registros totales cumplen estas condiciones?

---

## ğŸ§© MÃ“DULO 6: Sensor por EntropÃ­a

**Complejidad:** â­â­â­â­â­

### DesafÃ­o AVANZADO
No uses moda simple. Encuentra el sensor mÃ¡s "significativo":

1. Calcula la distribuciÃ³n de frecuencias de sensores
2. Identifica sensores que aparecen en al menos el **10%** de registros
3. De esos, toma el sensor con **ID mÃ¡s alto**
4. Invierte sus dÃ­gitos

### ğŸ’¡ CÃ³digo
```python
frecuencias = df['Sensor_ID'].value_counts()
porcentajes = frecuencias / len(df) * 100

# Sensores significativos (>=10%)
sensores_sign = frecuencias[porcentajes >= 10]

# ID mÃ¡s alto entre los significativos
sensor_seleccionado = sensores_sign.index.max()
sensor_invertido = int(str(sensor_seleccionado)[::-1])
```

### ğŸ¤” JustificaciÃ³n
Sensores raros pueden ser ruido. Queremos sensores relevantes pero preferimos IDs altos (mÃ¡s recientes).

---

## ğŸ§© MÃ“DULO 7: DesviaciÃ³n Temporal Robusta (MAD)

**Complejidad:** â­â­â­â­â­

### DesafÃ­o ESTADÃSTICO AVANZADO
No uses desviaciÃ³n estÃ¡ndar. Usa **MAD (Median Absolute Deviation)**:

$$MAD = median(|x_i - median(x)|)$$

1. Convierte timestamps a segundos
2. Calcula la mediana de los timestamps
3. Calcula las desviaciones absolutas respecto a la mediana
4. La MAD es la mediana de esas desviaciones
5. Convierte a MM:SS

### ğŸ’¡ ImplementaciÃ³n
```python
ts_segundos = df['Timestamp'].apply(lambda x: x.timestamp())
mediana_ts = ts_segundos.median()
desviaciones_abs = abs(ts_segundos - mediana_ts)
mad = desviaciones_abs.median()

# Convertir a MM:SS
minutos = int(mad // 60)
segundos = int(mad % 60)
codigo = f"{minutos:02d}:{segundos:02d}"
```

### ğŸ“Š Ventaja de MAD
MAD es extremadamente robusta contra outliers temporales.

---

## ğŸ§© MÃ“DULO 8: Ciudad por Ãndice de ConcentraciÃ³n

**Complejidad:** â­â­â­â­

### DesafÃ­o COMPLEJO
1. Calcula el **Ãndice de Herfindahl** (concentraciÃ³n) para ciudades:
   $$H = \sum_{i=1}^{n} p_i^2$$
   donde $p_i$ es la proporciÃ³n de cada ciudad

2. Si H > 0.25 (alta concentraciÃ³n): usa la ciudad mÃ¡s frecuente
3. Si H â‰¤ 0.25 (baja concentraciÃ³n): usa la ciudad con mayor energÃ­a promedio

4. Cuenta las letras de la ciudad seleccionada

### ğŸ’¡ CÃ³digo Herfindahl
```python
frecuencias = df['Ciudad'].value_counts()
proporciones = frecuencias / len(df)
indice_h = (proporciones ** 2).sum()

if indice_h > 0.25:
    ciudad = frecuencias.idxmax()
else:
    ciudad = df.groupby('Ciudad')['Energia'].mean().idxmax()

num_letras = len(ciudad)
```

### ğŸ¯ InterpretaciÃ³n
- H cerca de 1: una ciudad domina
- H cerca de 0: ciudades distribuidas uniformemente

---

## ğŸ§© MÃ“DULO 9: CorrelaciÃ³n de Spearman

**Complejidad:** â­â­â­â­â­

### DesafÃ­o AVANZADO
No uses correlaciÃ³n de Pearson. Usa **correlaciÃ³n de Spearman** (basada en rangos):

1. Calcula la correlaciÃ³n de Spearman entre `Nivel_Amenaza` y `Energia`
2. Spearman es mÃ¡s robusta ante relaciones no-lineales
3. Aplica la regla del dial (positivaâ†’9, negativaâ†’1)

### ğŸ’¡ CÃ³digo
```python
from scipy.stats import spearmanr

correlacion, p_valor = spearmanr(df['Nivel_Amenaza'], df['Energia'])
dial = 9 if correlacion > 0 else 1
```

### ğŸ“Š Spearman vs Pearson
```python
pearson = df['Nivel_Amenaza'].corr(df['Energia'])
print(f"Pearson: {pearson:.3f}")
print(f"Spearman: {correlacion:.3f}")
```

Â¿Por quÃ© pueden diferir?

---

## ğŸ§© MÃ“DULO 10: Checksum CriptogrÃ¡fico

**Complejidad:** â­â­â­â­

### DesafÃ­o MODIFICADO
Usa una fÃ³rmula mÃ¡s compleja:

$$Checksum = (M1 \times 2 + M5 + M8) \mod 10$$

Nota el **multiplicador 2** en M1 (porque usaste suma ponderada).

### ğŸ’¡ CÃ³digo
```python
m1_bits = bin(int(suma_ponderada)).count('1') if suma_ponderada > 50 else int(suma_ponderada)
checksum = (m1_bits * 2 + m5_valor + m8_valor) % 10
```

---

## ğŸ“ CONCEPTOS ESTADÃSTICOS APLICADOS

| Concepto | MÃ³dulo | RazÃ³n |
|----------|--------|-------|
| Media armÃ³nica | M2 | Penaliza valores bajos |
| Percentiles | M3 | Robustez contra outliers |
| Mediana | M4 | Medida de tendencia central robusta |
| MAD | M7 | DesviaciÃ³n robusta |
| Ãndice Herfindahl | M8 | Mide concentraciÃ³n |
| CorrelaciÃ³n Spearman | M9 | Detecta relaciones monotÃ³nicas |

---

## ğŸ”¬ PREGUNTAS DE ANÃLISIS PROFUNDO

1. **M2:** Â¿CÃ³mo difiere el promedio armÃ³nico del aritmÃ©tico? Â¿CuÃ¡l es mayor?
2. **M3:** Â¿CuÃ¡ntos valores quedan fuera del rango P10-P90?
3. **M5:** Â¿QuÃ© porcentaje de agentes estÃ¡n en riesgo extremo?
4. **M7:** Â¿CÃ³mo se compara MAD vs desviaciÃ³n estÃ¡ndar?
5. **M8:** Â¿El Ã­ndice H indica concentraciÃ³n alta o baja?
6. **M9:** Â¿Hay diferencia significativa entre Pearson y Spearman?

---

## ğŸ¯ CHECKLIST EXPERTO

- [ ] Usaste suma **ponderada** en M1
- [ ] Aplicaste promedio **armÃ³nico** en M2
- [ ] Usaste **percentiles** en M3
- [ ] Calculaste **mediana** por cable en M4
- [ ] Triple filtro en M5
- [ ] EntropÃ­a de sensores en M6
- [ ] MAD (no STD) en M7
- [ ] Ãndice Herfindahl en M8
- [ ] Spearman (no Pearson) en M9
- [ ] Checksum con multiplicador en M10

---

## ğŸš€ DESACTIVACIÃ“N

1. `index.html`
2. ContraseÃ±a: **B-03**
3. â±ï¸ **20:00 minutos**

---

**Esta bomba requiere maestrÃ­a estadÃ­stica. Â¡ConfÃ­a en tu anÃ¡lisis! ğŸ“ŠğŸ”¬ğŸ’£**

---

*ClasificaciÃ³n: ULTRA SECRETO | OperaciÃ³n Ãcaro | Bomba B-03*
